极大似然估计： Maximum likelihood estmation(MLE)

Source：http://hbanaszak.mjr.uw.edu.pl/TempTxt/Myung_2002_TutorialOnMaximumLikelihoodEstimation.pdf

    本节尝试着记录一些学习MLE时查阅到的资料，简单翻一下
    
    假设我们有一个带参数的模型，以及一些收集到的观测数据，这时候我们要根据观测数据来评估模型的参数，即统计学概念上的参数估计。一般来说有两大类参数估计的方法，一个是最小二乘法, Least-Square Estimation(LSE), LSE衍生出了许多概念，比如离差平方和，线性回归，R2系数等。LSE，不像MLE，它不需要对总体数据的概率分布做任何假设，就可以直接计算模型的参数。主要用于对观测数据做出一个描述性很强的测度，但是同样它也失去了进一步做假设检验和置信区间估计的基础
    
    从统计学角度来说，观测数据向量 y = (y1, y2, ..., ym) 是一个未知总体的随机抽样。数据分析的目的就是去找出最有可能产生这个样本的总体，在统计学中，每个总体都具备一个相关的概率分布，而与概率分布相关联的就是这个模型的各种参数。参数一旦发生变化，模型的概率分布也随之变化。
    
    1. 概率密度函数 probability density function (PDF)
    
    令 f(y|w) 表示向量y的概率密度函数，w是概率模型的参数，w=(w1, w2, ..., wk), 总共有k个参数
    
    那么假如每个观测值yi都是相互独立的，那么向量y的概率密度函数则是：
    
    f(y = (y1, y2, ..., ym) | w) = f(y1|w) * f(y2|w) * f(y3|w) * ... * f(ym|w)
    
    我们看最简单的一种情况，二项分布，做10次伯努利实验，每次的成功率为0.2，y是十次实验里面成功的次数，那么参数是(n, w) = (10, 0.2), 概率密度函数
    
    f(y|n = 10, w = 0.2) = Combine(10, y) * Power(0.2, y) * Power(0.8, 10-y), y = 0, 1, ..., 10
    
    将其一般化则是
    
    f(y|n, w) = Combine(n, y) * Power(w, y) * Power(1-w, n-y) 
     
    2. 似然函数 likelihood function 
    
    给定模型的一组参数之后，我们可以计算出某些观测数据发生的概率要比其它的高，比如上面的二项分布(10, 0.2), P(y = 2) = 0.302, P(y = 5) = 0.026, 那么做这10次伯努利试验，成功2次的概率要大于成功5次的概率。 那么我们很容易联想到一个相反的问题，就是给定一组观测数据，能否倒过来计算哪种参数的可能性最大？为了求解这个问题，我们定义似然函数：将观测向量y和参数向量w的角色互换
    
    L(w|y) = f(y|w)
    
    这样L(w|y)就表示对于给定的观测数据y，参数w为某值的可能性(likelihood)是多少，这样一来L(w|y)就是一个关于w 的函数了，比如对于上面的二项分布，我们给定 y = 7, n = 10 那么这时候：
    
    L(w|y = 7, n = 10) = f(y = 7 | n = 10, w) = Combine(10, 7) * Power(w, 7) * Power(1-2, 3) = 120*w**7*(1-w)**3
    
    这样的话L(w|y)就是一个关于w的抛物线，一般而言，假如w是一个k维的向量空间，那么L就是在此向量空间上面的某个k维几何曲面

    这样一来我们就可以求这个函数的极大值，得出w为多少时，L值最大，即每一次成功的概率是多少时，最终观测数据为7的可能性最大
    
    推而广之，可以得出极大似然估计的定义，由R.A.Fisher在1920年代提出，是说“最有可能”产生观测数据的参数估计叫极大似然估计。这样一来，求解极大似然估计似乎又成了一个典型的最优化问题了。
    
    根据微积分原理求解MLE
    1. 函数L(w|y)是关于w向量(w1, w2,..., wk)的多元函数，那么分别求解每个变量wi的导数：
    
        d(L)/d(wi) = 0 来求解每个wi值
        
    2. 因为一阶导数为0只是保证该点是个极值点，但不保证是极大值，所以要继续求二阶导数，如果f''(L)/d(wi) < 0 才能保证是个极大值点
    
    在计算过程中，因为L(w|y)通常是关于w的高阶函数，计算很不方便，所以通常使用它的对数来简化计算，因为L与ln(L)的单调性严格一致，所以可以保证求极值的解是一样的，
    
    以上式为例： ln(L) = ln(120) + 7ln(w) + 3ln(1-w), d(ln(L)) = 7/w - 3/(1-w) = (7 - 10w) / [w(1 - w)]
    
    所以 w = 0.7 时，一阶导数为0，验证其二阶导数，发现此时f''(Ln(L)) = -47.62 < 0
    
    于是 w = 0.7 即是极大似然估计
      
