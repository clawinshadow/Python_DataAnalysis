Wikipedia 讲的很好：
https://en.wikipedia.org/wiki/Perceptron

在机器学习中，感知机是一种用于二分类问题的有监督学习算法，是一种线性分类器，支持在线学习。但是一层的感知机只能识别线性可分的漠视，甚至连XOR异或问题都搞不定。

定义：

一般来说，感知机是一种算法，用来学习出一个二分类器：即一个函数，输入为向量x，输出是f(x):
       
f(x) = if w*x + b > 0 ? 1 : 0

w就是相应的权重向量，个数与x的维度一致，b是偏移量bias，决定了决策边界与原点之间的距离，与输入x是什么没有关系。如果训练数据集不是线性可分的，那么感知机学习算法将永远不能终止。在神经网络中，一个感知机就是一个使用Heaviside step function(单位阶跃函数)作为激活函数的人造神经元，感知机算法也被称为单层感知机，以便于多层感知机区分开来，作为一个线性分类器，单层感知机是最简单的前向反馈神经网络

与其他线性分类算法比如logistic回归不同，感知机不需要一个学习率之类的参数，因为即使加上这个参数，也只是缩放了权重，而不会改变预测结果的正负，即0和1不会改变

先转换一下数据集，在最前面加一列全为1，即x[:, 0] = 1, 对应的权重为w[0], 这个就是bias，替代上面所说的b

w[i][t]表示第i个权重在第t次迭代中的值

D = {(x1, d1), ... , (xs, ds)}, dj表示每个样本的目标分类


步骤：
1. 给定权重的初始值和算法结束的阈值，一般权重都初始化为0或者很小的随机值

2. 对训练数据集D中每个样本j，循环执行以下的计算：

    a. 计算如下 输出：
    
       y[j][t] = f[w(t) * xj] = f[w[0][t]*x[j][0] + w[1][t]*x[j][1] + ... + w[n][t]*x[j][n]]
       
    b. 更新权重向量
    
       w[i][t+1] = w[i][t] + (dj - y[j][t])*x[j][i]
       
3. 以上是在线学习算法，对于离线的学习，只需要重复第二步就可以，遍历完整个训练数据集，直到迭代错误之和和均值

    1/s * sigma(|dj - y[j][t]|)
    
   小于用户定义的阈值，或者是达到了预先定义的一个迭代次数的上限
   
收敛性：

感知机是一个线性分类器，所以对于那些线性不可分的训练数据集D，它永远达不到有效的分类状态，更具体地说，如果positive和negative的样本不能通过一个超平面完全分隔开，那么随着算法的进行，将不会得到一个越来越“接近”的分类结果，而是彻彻底底的分类失败。所以如果我们不能事先确定训练集是否线性可分的话，不能贸然使用感知机，应该使用它的某个变种，但是如果能保证线性可分，那么感知机算法就一定会收敛
